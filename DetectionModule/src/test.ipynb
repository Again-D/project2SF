{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38610994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 로드 중: wsl_best.pt\n",
      "모델 로드 완료.\n",
      "영상 스트림 연결 중: http://192.168.0.124:8001/stream.mjpg\n",
      "영상 스트림 연결 성공.\n",
      "\n",
      "영상 스트림으로부터 프레임을 읽고 감지를 시작합니다.\n",
      "감지 결과를 보려면 True 설정을 확인하세요.\n",
      "'q' 키를 누르면 감지를 종료합니다.\n",
      "\n",
      "감지 및 영상 스트림 처리가 종료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2 as cv\n",
    "\n",
    "\n",
    "# 1. 커스텀 학습된 YOLO 모델 가중치 파일 경로 (.pt)\n",
    "MODEL_PATH = \"wsl_best.pt\"\n",
    "\n",
    "# 2. 라즈베리 파이 카메라 서버의 영상 스트림 주소 (URL)\n",
    "VIDEO_STREAM_URL = 'http://192.168.0.124:8001/stream.mjpg'\n",
    "\n",
    "# 3. 탐지 임계값 (Confidence Threshold)\n",
    "CONF_THRESHOLD = 0.3 # 필요에 따라 조정하세요 (예: 0.3, 0.7 등)\n",
    "\n",
    "# 4. IOU 임계값 (NMS IoU Threshold)\n",
    "\n",
    "# 5. 결과 시각화 창 표시 여부\n",
    "SHOW_DETECTION_WINDOW = True\n",
    "\n",
    "# model= YOLO(\"wsl_best.pt\")\n",
    "\n",
    "# --- YOLO 모델 로드 ---\n",
    "try:\n",
    "    print(f\"모델 로드 중: {MODEL_PATH}\")\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    print(\"모델 로드 완료.\")\n",
    "except Exception as e:\n",
    "    print(f\"모델 로드 오류가 발생했습니다: {e}\")\n",
    "    print(\"모델 파일 경로를 확인하거나, 파일이 손상되지 않았는지 확인하세요.\")\n",
    "    exit()\n",
    "\n",
    "# --- 영상 스트림 열기 ---\n",
    "print(f\"영상 스트림 연결 중: {VIDEO_STREAM_URL}\")\n",
    "# cv2.VideoCapture 객체를 생성하여 영상 스트림을 엽니다.\n",
    "# OpenCV가 FFmpeg와 함께 빌드되어 있어야 네트워크 스트림 처리가 가능합니다.\n",
    "cap = cv.VideoCapture(VIDEO_STREAM_URL)\n",
    "\n",
    "# 스트림이 제대로 열렸는지 확인\n",
    "if not cap.isOpened():\n",
    "    print(f\"오류: 영상 스트림을 열 수 없습니다. 다음을 확인하세요:\")\n",
    "    print(f\"- 영상 스트림 URL: {VIDEO_STREAM_URL} 이 올바른지.\")\n",
    "    print(\"- 라즈베리 파이 카메라 서버가 실행 중인지.\")\n",
    "    print(\"- 네트워크 방화벽 설정 (포트가 열려 있는지).\")\n",
    "    print(\"- OpenCV가 FFmpeg를 지원하며 네트워크 스트림 처리가 가능한지.\")\n",
    "    exit()\n",
    "print(\"영상 스트림 연결 성공.\")\n",
    "\n",
    "# --- 영상 프레임 읽고 감지 수행 ---\n",
    "print(\"\\n영상 스트림으로부터 프레임을 읽고 감지를 시작합니다.\")\n",
    "print(f\"감지 결과를 보려면 {SHOW_DETECTION_WINDOW} 설정을 확인하세요.\")\n",
    "print(\"'q' 키를 누르면 감지를 종료합니다.\")\n",
    "\n",
    "# Optional: FPS 계산을 위한 변수 초기화\n",
    "# start_time = time.time()\n",
    "# frame_count = 0\n",
    "\n",
    "while True:\n",
    "    # 영상 스트림에서 프레임 하나를 읽어옵니다.\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # 프레임을 제대로 읽지 못했다면 (예: 스트림 종료, 연결 끊김 등) 루프 종료\n",
    "    if not ret:\n",
    "        print(\"영상 스트림에서 프레임을 더 이상 읽을 수 없습니다. 스트림이 종료되었거나 오류가 발생했습니다.\")\n",
    "        break\n",
    "\n",
    "    # Optional: 읽은 프레임 크기 확인 (디버깅용)\n",
    "    # if frame is not None:\n",
    "    #     print(f\"읽은 프레임 크기: {frame.shape}\")\n",
    "\n",
    "    # 현재 프레임에 대해 객체 감지 수행\n",
    "    # model.predict() 메소드는 이미지 파일 경로, OpenCV 프레임(NumPy 배열), PIL Image 등 다양한 소스를 입력받습니다.\n",
    "    # source=frame으로 읽은 OpenCV 프레임을 직접 전달합니다.\n",
    "    # conf, iou 인자로 탐지 결과 필터링 임계값을 설정합니다.\n",
    "    # verbose=False로 설정하면 감지 과정 상세 출력을 끕니다.\n",
    "    results = model.predict(\n",
    "        source=frame,\n",
    "        conf=CONF_THRESHOLD,\n",
    "    \n",
    "        # show=True # Ultralytics 자체 시각화 (여기서는 cv2.imshow 사용을 위해 끕니다)\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # 감지 결과 프레임 가져오기\n",
    "    # model.predict(source=frame)은 해당 프레임에 대한 결과 객체의 리스트를 반환합니다.\n",
    "    # 결과가 하나뿐이므로 results[0]을 사용합니다.\n",
    "    # .plot() 메소드는 탐지 결과 (바운딩 박스, 라벨 등)가 그려진 NumPy 배열 형태의 이미지를 반환합니다.\n",
    "    annotated_frame = results[0].plot() # <-- results[0] 객체에 .plot() 메소드 호출\n",
    "\n",
    "    # 결과 화면 표시 (설정된 경우)\n",
    "    if SHOW_DETECTION_WINDOW:\n",
    "        # cv2.imshow() 함수를 사용하여 시각화된 프레임을 창에 표시합니다.\n",
    "        cv.imshow(\"YOLO Object Detection from RPi Stream\", annotated_frame)\n",
    "\n",
    "    # Optional: FPS 계산 및 출력\n",
    "    # frame_count += 1\n",
    "    # if (time.time() - start_time) > 1: # 1초마다 FPS 계산\n",
    "    #    fps = frame_count / (time.time() - start_time)\n",
    "    #    print(f\"처리 FPS: {fps:.2f}\")\n",
    "    #    frame_count = 0\n",
    "    #    start_time = time.time()\n",
    "\n",
    "\n",
    "    # 키 입력을 대기하고 'q' 키가 눌리면 루프 종료\n",
    "    # cv2.waitKey(1)은 1ms 동안 키 입력을 대기합니다.\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- 자원 해제 ---\n",
    "cap.release() # cv2.VideoCapture 객체 해제 (스트림 연결 종료)\n",
    "if SHOW_DETECTION_WINDOW:\n",
    "    cv.destroyAllWindows() # 생성된 모든 OpenCV 창 닫기\n",
    "\n",
    "print(\"\\n감지 및 영상 스트림 처리가 종료되었습니다.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
